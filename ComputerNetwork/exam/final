------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------------ [1] Transport Layer의 Process-to-Process 전송이 어떤 의미인지 설명합니다. ------------------

전송 계층은 [프로세스 간 전달, 즉 메시지의 일부인 패킷을 한 프로세스에서 다른 프로세스로 전달하는 역할]을 담당합니다.
두 프로세스는 클라이언트/서버 관계로 통신한다. 해당 통신에서는 socket으로 통신하며 socket은 ip + port로 구성되어 있다.\

클라이언트  : 로컬 호스트의 프로세스
서버        : 원격 호스트에서 서비스를 제공하기 위한 프로세스이다.
두 프로세스(클라이언트 및 서버) 모두 동일한 이름을 갖는다.

통신을 위해서는 다음을 정의해야 합니다.
   1. 로컬 호스트
   2. 로컬 프로세스
   3. 원격 호스트
   4. 원격 프로세스

node-to-node        : data-link
Host-to-Host        : Network-link
Process-to-Process  : Transport-link

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------------ [2] TCP/UDP의 헤더 정보에서 Process-to-Process 전송이 가능하게 하는 필드는 무엇이고, 어떤 용도로 사용하는지 설명합니다. ------------------

"Port Number"로써 TCP에서 제공되는 ip헤더와 tcp헤더를 통해서 tcp/socket 통신을 진행한다. 
TCP 헤더와 UDP 헤더에는 송신 프로세스를 나타내는 출발지 포트 번호와 수신 프로세스를 나타내는 목적지 포트 번호가 있다.
ip는 host의 주소를 찾는 변수이다.
이후 주소값에 들어간 Transport 정보는 Port 번호를 통해서 프로세스를 선택하여 어떤 프로세스에 들어갈 지 정하여 들어간다.
호스트 내에서 다수의 프로세스가 존재하며 네트워크를 사용한다. Port 번호를 통해 어떤 프로세스로 데이터를 전달해야 하는지를 식별할 수 있으므로, Process-to-Process 전송이 가능하다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------------ [3] OSI 2계층에서 에러 검출 및 복구를 하지만, 4계층에서도 에러 검출 및 복구를 해야하는 이유를 설명합니다. ------------------


대답은 '예'입니다.
인터넷의 네트워크 계층은 신뢰할 수 없습니다(최선의 노력 전달). 전송 계층에서 안정성을 구현해야 합니다.

신뢰할 수 없는 서비스
응용 계층 프로그램이 자체 흐름 및 오류 제어 메커니즘을 사용하므로 신뢰성이 필요하지 않은 경우
통신은 아무리 잘 전달되어 에러가 언제 어디서나 있다고 하는게 옳으며, 이를 미리 계산해서 통신 계층안에서의 안정성을 확보해야 한다.

믿을 수 있는 서비스
응용 계층 프로그램에 신뢰성이 필요한 경우 TCP와 같은 신뢰성 있는 전송 프로토콜을 사용합니다.
SCTP. 이는 더 느리고 더 복잡한 서비스를 의미합니다.

또는 빠른 서비스가 필요하거나 서비스의 특성상 흐름 및 오류 제어(실시간 적용)를 요구하지 않는 경우 UDP와 같은 신뢰할 수 없는 프로토콜을 사용할 수 있습니다.

주로 세그먼트의 전송과 관련된 에러 검출 및 복구를 수행합니다. 

 **4계층에서의 에러 검출 및 복구:**
   - **역할:** 전송 계층은 송신 호스트와 수신 호스트 간의 신뢰성 있는 데이터 전송을 담당하며, 세그먼트의 전송, 흐름 제어, 오류 검출, 복구 등을 수행합니다.
   - **이유:** 데이터의 전송 중에는 네트워크의 혼잡, 패킷 손실, 네트워크 장애 등 다양한 이유로 에러가 발생할 수 있습니다. 이러한 에러는 주로 2계층에서는 처리하기 어렵고, 전송 계층에서 보다 효과적으로 처리할 수 있습니다. 에러를 더 높은 계층에서 처리함으로써 네트워크 전체의 효율성과 신뢰성을 높일 수 있습니다.

4계층에서는 전송 중에 발생하는 네트워크 상의 이슈로 인한 에러를 처리하여 신뢰성 있는 데이터 전송을 보장합니다. 각 계층의 역할과 책임에 따라 에러 검출 및 복구가 분리되어 수행되는 것이 효과적입니다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------------ [4] UDP는 에러 검출 및 복구를 하지 않지만, 그럼에도 불구하고 사용을 하는 이유를 설명합니다. ------------------

UDP의 헤더에는 source port address, Destination port address, UDP total length 그리고 Checksum으로 구성되어 있고, Checksum으로만 보안인증을 진행함.

UDP(사용자 데이터그램 프로토콜)는 연결이 없고 신뢰할 수 없는 전송 프로토콜이라고 합니다. 
호스트 간 통신 대신 프로세스 간 통신을 제공하는 것 외에는 IP 서비스에 아무것도 추가하지 않습니다.

UDP가 그렇게 무력하다면 프로세스는 왜 이를 사용하려고 할까요? 
프로세스가 작은 메시지를 보내고 안정성에 크게 신경 쓰지 않는 경우 최소한의 오버헤드를 사용하는 매우 간단한 프로토콜입니다. 
작은 메시지를 보내는 경우 UDP를 사용할 수 있으며 TCP를 사용하는 것보다 발신자와 수신자 간의 상호 작용이 훨씬 적습니다.

흐름 및 오류 제어:
흐름 제어가 없으므로 윈도우가 없습니다.

mechanism:
UDP에는 체크섬을 제외하고는 오류 제어 메커니즘이 없습니다.

캡슐화 및 캡슐화 해제:
UDP 프로토콜은 IP 데이터그램의 메시지를 캡슐화하고 캡슐화 해제합니다.
선택적으로 에러 처리 및 복구가 필요 없는 경우에는 UDP를 사용하여 성능을 향상시킬 수 있습니다. -> 속도가 빠름

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ 
------------------ [5] TCP의 에러 검출과 복구 동작을 TCP의 헤더 필드를 사용하여 설명합니다. ------------------

TCP(Transmission Control Protocol)는 신뢰성 있는 데이터 전송을 위해 여러 제어 비트를 사용합니다. 여러 TCP 플래그 중에서 URG, ACK, PSH, RST, SYN, FIN은 주로 에러 검출 및 복구 동작과 관련된 역할을 수행합니다.

1. **URG (Urgent):**
   - **에러 검출 및 복구:** URG 플래그는 긴급 데이터의 존재를 나타냅니다. 긴급 데이터는 전송 중에 높은 우선순위로 처리되어야 하는 데이터를 의미합니다. 에러 검출과 복구와 직접적인 관련은 없지만, 긴급 데이터의 존재를 알려 에러에 대한 조치를 취할 수 있습니다.
2. **ACK (Acknowledgment):**
   - **에러 검출 및 복구:** ACK 플래그는 데이터의 정상적인 수신을 확인하는 데 사용됩니다. 에러가 발생하면 재전송이 요청될 수 있습니다. ACK 플래그는 데이터 손실을 검출하고 복구하는데 도움이 됩니다.
3. **PSH (Push):**
   - **에러 검출 및 복구:** PSH 플래그는 데이터를 즉시 전송하라는 의미를 갖습니다. 데이터 전송에 대한 높은 우선순위를 갖기 때문에, 에러가 감지되면 해당 데이터를 빠르게 재전송하여 복구할 수 있습니다.
4. **RST (Reset):**
   - **에러 검출 및 복구:** RST 플래그는 연결을 초기화하거나 문제가 발생했을 때 사용됩니다. 에러가 심각한 경우, 연결을 재설정하여 상태를 초기화하고 에러에 대한 조치를 취할 수 있습니다.
5. **SYN (Synchronize):**
   - **에러 검출 및 복구:** SYN 플래그는 TCP 연결을 초기화하는데 사용됩니다. 에러가 없는 정상적인 연결 설정의 일부로 사용되며, 이 단계에서 에러가 발생하면 연결이 성립되지 않을 수 있습니다.
6. **FIN (Finish):**
   - **에러 검출 및 복구:** FIN 플래그는 연결을 종료할 때 사용됩니다. 정상적인 연결 종료의 일부로 사용되며, 이 단계에서 에러가 발생하면 종료 과정이 중단될 수 있습니다.
이러한 플래그들은 TCP 헤더에 포함되어 있으며, 네트워크 통신에서 데이터 전송의 신뢰성과 에러 복구를 돕는데 중요한 역할을 합니다.


세그먼트 번호 값에 대한 필드가 없습니다. 
대신 시퀀스 번호와 승인 번호라는 두 개의 필드가 있습니다.
이 두 필드는 바이트 번호를 나타냅니다.
각 연결에서 전송되는 모든 데이터 바이트는 TCP로 번호가 지정됩니다.
번호 매기기는 무작위로 생성된 번호로 시작됩니다.
첫 번째 바이트의 번호 범위 : 0 ~ 2 32 -1 (임의의 번호가 1,057이고 총 개수가 6,000바이트인 경우 바이트 번호는 1,057부터 7,056까지입니다.
Byte numbering is used for flow and error control


바이트가 번호화되면 TCP는 전송되는 각 세그먼트에 시퀀스 번호를 할당합니다.
각 세그먼트의 세그먼트 번호는 해당 세그먼트에 포함된 첫 번째 바이트의 번호입니다.
세그먼트의 승인 필드 값은 당사자가 수신할 것으로 예상하는 다음 바이트 수를 정의합니다. 승인번호는 누적됩니다.


TCP의 에러 검출과 복구 동작은 주로 다양한 헤더 필드와 플래그를 사용하여 구현됩니다. 아래에서는 TCP의 헤더 필드를 중심으로하여 에러 검출과 복구 동작을 설명합니다.

1. **Checksum (체크섬):**
   - TCP 헤더에는 16비트 체크섬 필드가 있습니다. 이 필드는 TCP 세그먼트의 오류를 검출하는 데 사용됩니다.
   - 송신 측은 TCP 세그먼트를 전송하기 전에 데이터와 헤더에 대한 체크섬을 계산하고 이 값을 체크섬 필드에 포함시킵니다.
   - 수신 측은 받은 세그먼트에 대해 체크섬을 다시 계산하고, 송신 측의 체크섬과 비교하여 오류를 검출합니다.
   - 체크섬이 일치하지 않으면 수신 측은 오류로 판단하고 해당 세그먼트를 폐기합니다.

2. **Acknowledgment Number (확인 번호) 및 Retransmission (재전송):**
   - 수신 측은 올바르게 수신된 데이터에 대한 확인을 송신 측에게 알리기 위해 확인 번호를 사용합니다.
   - 송신 측은 일정 시간 내에 확인을 받지 못하면 해당 데이터가 손실되었다고 판단하고, 해당 데이터를 재전송합니다.

3. **Window Size (윈도우 크기):**
   - 윈도우 크기 필드는 TCP 세그먼트 헤더에 포함되어 있습니다. 이는 수신 측이 현재 받을 수 있는 데이터의 양을 나타냅니다.
   - 수신 측은 윈도우 크기를 조절하여 송신 측에게 데이터를 얼마나 많이 전송할 수 있는지 알려줍니다.
   - 효과적인 흐름 제어를 통해 데이터의 오버플로우를 방지하고, 복구 시간을 최소화합니다.

4. **Selective Acknowledgment (선택적 확인) 및 SACK 옵션:**
   - SACK 옵션을 사용하여 수신 측은 어떤 데이터가 손상되었는지를 세밀하게 알려줄 수 있습니다.
   - 송신 측은 SACK 옵션을 통해 전송이 실패한 부분에 대한 재전송을 수행할 수 있습니다.

5. **Retransmission Timeout (재전송 시간 초과):**
   - TCP은 재전송 타이머를 사용하여 수신 측으로부터 일정 시간 내에 확인을 받지 못한 경우 해당 데이터를 재전송합니다.
   - 재전송 타이머를 조절하여 네트워크 상황에 적응하며, 성능을 최적화합니다.

TCP의 헤더 필드와 동작을 조합하여, 송신 측과 수신 측 간의 신뢰성 있는 통신이 가능하도록 에러 검출과 복구 메커니즘이 구현됩니다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------------ [6] TCP의 흐름 제어 동작을 TCP의 헤더 필드를 사용하여 설명합니다. ------------------

TCP의 흐름 제어는 수신 측이 송신 측에게 데이터의 흐름을 적절하게 조절하도록 하는 메커니즘입니다. 
이러한 동작은 TCP 헤더의 여러 필드를 통해 이뤄지며, 주요한 헤더 필드와 동작을 설명합니다.

1. **Sequence Number (순서 번호):**
   - TCP 세그먼트의 헤더에는 데이터의 순서 번호가 포함됩니다.
   - 수신 측은 이 순서 번호를 사용하여 송신 측으로부터 수신한 데이터의 순서를 파악합니다.
   - 순서 번호를 통해 수신 측은 송신 측에게 어떤 데이터가 수신되었는지 알립니다.

2. **Acknowledgment Number (확인 번호):**
   - 수신 측은 확인 번호를 사용하여 송신 측에게 성공적으로 수신했다는 사실을 알립니다.
   - 수신 측은 확인 번호로 송신 측에게 다음에 기대되는 데이터의 순서를 알려줍니다.
   - 이를 통해 송신 측은 수신 측의 상태를 파악하고 데이터의 흐름을 조절합니다.

3. **Window Size (윈도우 크기):**
   - TCP 헤더에는 16비트로 표현되는 윈도우 크기 필드가 있습니다.
   - 윈도우 크기는 수신 측이 현재 받을 수 있는 데이터의 양을 나타냅니다.
   - 송신 측은 이 윈도우 크기를 고려하여 데이터를 전송하며, 수신 측은 이를 조절하여 흐름을 제어합니다.

4. **Flow Control Process (흐름 제어 프로세스):**
   - 송신 측이 데이터를 전송할 때, 수신 측은 윈도우 크기를 통해 얼마나 많은 데이터를 받을 수 있는지 알려줍니다.
   - 수신 측의 윈도우 크기를 고려하여 송신 측은 특정 시점에 보낼 수 있는 데이터의 양을 조절합니다.
   - 이로써 수신 측은 과부하를 방지하고 자신의 수신 속도에 맞게 데이터를 수용할 수 있습니다.

이러한 헤더 필드와 동작을 통해 TCP는 흐름 제어를 수행하여 송수신 간의 데이터 전송을 효율적으로 관리합니다. Flow control은 네트워크 혼잡을 방지하고 안정적인 통신을 제공하는데 기여합니다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[7] TCP의 혼잡 제어 동작을 TCP의 cwnd 값을 관리하는 2가지 방식을 사용하여 설명합니다.


TCP의 혼잡 제어(Congestion Control)는 네트워크 혼잡을 효과적으로 관리하여 성능을 최적화하는 데 중요한 역할을 합니다. 혼잡 제어는 TCP의 윈도우 크기를 동적으로 조절하여 네트워크의 혼잡 상태에 대응합니다. 윈도우 크기는 cwnd(혼잡 윈도우)라는 변수를 통해 관리되며, 이 값은 두 가지 방식을 사용하여 조절됩니다.

1. **AIMD (Additive Increase, Multiplicative Decrease):**
   - **증가 (Additive Increase):** TCP는 혼잡이 발생하지 않을 때, 일정한 주기(라운드 트립 타임)마다 cwnd를 1씩 증가시킵니다. 이것이 증가라는 용어의 유래입니다. 이는 네트워크의 이용 가능한 대역폭을 효과적으로 활용하는 방법입니다.
   - **감소 (Multiplicative Decrease):** 혼잡이 발생하면, 즉 패킷 손실이 감지되면 TCP는 cwnd를 반으로 줄입니다. 이는 혼잡을 감지했으므로 네트워크의 용량을 줄이고 다시 적응하는 것입니다.

2. **Slow Start:**
   - 초기에는 빠르게 증가시키는 방식으로 동작합니다. 연결이 시작될 때, cwnd는 1부터 시작하고, 매번 성공적으로 패킷이 전송될 때마다 cwnd를 두 배씩 증가시킵니다. 이는 네트워크의 초기 상태에서 가능한 한 빠르게 대역폭을 활용하기 위한 것입니다.
   - 단, Slow Start는 cwnd가 어떤 임계값(threshold)까지만 증가하면 AIMD로 전환됩니다. 이후에는 AIMD 방식으로 윈도우 크기를 관리하게 됩니다.

이러한 방식들을 조합하여 TCP는 네트워크 혼잡에 유연하게 대응하며, 최적의 성능을 유지하려고 노력합니다. AIMD와 Slow Start은 TCP의 혼잡 제어 동작을 설명하는 핵심 개념 중 일부입니다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[8] Socket 프로그래밍에서 서버와 클라이언트의 동작 절차를 주요 함수 기준으로 설명합니다.

client                  server
---------------------------------
socket                  socket   |                                  1) 첫 번째 단계는 소켓을 생성하는 단계
  |                       |      |
  |                      bind    | open listen                      2) 서버가 사용할 ip주소와 port 번호를 결합
  |                       |      |
  |                     listen   |                                  3) client로부터 요청이 수신되는지 확인
  |    connect request    |
connect ------------->    |                                         4) ip주소와 포트번호로 식별되는 대상에게 연결 요청을 보낸다. / block 방식(결과가 결정되기 전까지는 connect() 실행 안끝남)
  |                     accept                                      5) 데이터 통신을 위한 소켓을 생성한다.
---------------------------------
| write                   read  | client server
| read                    write |    session                        6)  send()와 recv()로 데이터 교환 
---------------------------------
  |                       |
close                    read
                          |
                        close                                     7) 소켓을 닫게됨


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[9] 사용자의 URL 입력 이후 부터, HTTP Req가 HTTP Client에서 전송되기 전에 이뤄져야 하는 동작을 차례대로 설명합니다. (DNS Lookup, TCP 연결 설정)

오리지널 HTTP 1.1의 동작 방식이다.
1. url창을 입력함 (도메인 이름+port 이름(통상적으로 80을 입력함))
2. 웹브라우져는 DNS(Domain Name System) 작업을 통해 호스트 이름을 ip address로 바꿈.
3. 이후에 tcp 연결을 진행
  3-1. ip + port의 주소에 접근
  3-2. HTTP GET request 진행
  3-3. HTTP를 서버로 부터 읽는다.
  3-4. 3-1에서 연결된 connection을 끊는다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[10] HTTP의 4대 메시지를 나열하고, 각각의 기능, 그리고 각각에 대해서 REQ/RES에 포함하는 정보가 무엇인지 설명합니다.

GET: 
  request   : 주소/프로토콜(+버전)/Host 주소/받을 수 있는 정보
  response  : 프로토콜(+버전)/status code/context 타입/길이
PUT(파일을 업로드):
  request   : 파일위치(호스트 주소 아래에 있는)/프로토콜(버전)/Host 주소/content 타입/컨텐츠 길이/
  response  : 프토토콜(버전)/status code/저장된 위치(기본적으로 root)/content 타입/컨텐츠 길이
POST(정보 전달):
  request   : ?/프토토콜(버전)/호스트주소/컨텐츠 타입/컨텐츠 길이
  response  : 프로토콜(버전)/컨텐츠 타입/컨텐츠 길이
DELETE
  request   : 파일위치(target)/프로토콜(버전)/호스트 주소
  response  : 프로토콜(버전)/컨텐츠 타입/컨텐츠 길이





------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------ [11] HTTP/2의 다중화 기술은 HTTP/1.1과 어떤 점이 다르며, 어떻게 다중화가 가능한지 설명합니다. ------------


tcp를 순서대로 보내고 순서대로 받음 (최대 8개를 받음)
편법 : 
이전 1.1에서는 tcp만큼 세션을 뚫어서 진행했다.
하지만 2에 경우에는 stream으로 구성되며, Frame 단위로 끊어서 제공한다.
하나만 뚫어 놓고 안에서 frame 단위로 집어 넣어서 한 번에 전달함.
서버의 부화도 줄어듦. 1.1 시점에는 순차적으로 하나하나가고 하나하나 내려옴
서버 2는 한번에 복수적으로 처리를 할 수 있음

특정 조건에서는 좋다.

HTTP/2는 HTTP/1.1과 비교하여 다중화(Multiplexing) 기술에서 큰 개선을 제공합니다.
다중화는 여러 개의 요청과 응답을 동시에 처리하여 효율성을 향상시키는 메커니즘입니다. 
아래는 HTTP/2에서의 다중화와 HTTP/1.1과의 차이점에 대한 설명입니다.


### HTTP/1.1과의 차이점:
1. **Connection 개수:**
   - **HTTP/1.1:** 하나의 TCP 연결에서 한 번에 하나의 요청만 처리 가능합니다. 여러 개의 리소스를 가져오려면 복수의 연결이 필요했습니다.
   - **HTTP/2:** 단일 TCP 연결을 통해 여러 요청과 응답을 동시에 처리할 수 있습니다. 다중화는 여러 스트림을 하나의 연결에서 동시에 처리할 수 있도록 합니다.

2. **Head-of-Line Blocking 문제:**
   - **HTTP/1.1:** 한 번에 하나의 요청만 처리 가능하기 때문에 하나의 요청이 지연되면 그 이후의 요청도 기다려야 하는 Head-of-Line Blocking 문제가 발생할 수 있습니다.
   - **HTTP/2:** 다중화를 통해 다양한 요청과 응답이 병렬적으로 전송되기 때문에 하나의 요청이 지연되어도 다른 요청은 계속 처리됩니다.

3. **Header 압축:**
   - **HTTP/1.1:** 각 요청과 응답에는 중복되는 헤더 정보가 계속 전송되어 대역폭 낭비가 발생할 수 있습니다.
   - **HTTP/2:** 헤더 필드는 허프만 코딩 기반의 HPACK 압축 알고리즘을 사용하여 압축되어 전송되어 대역폭을 절약합니다.


### 다중화의 동작 방식:
1. **스트림 (Stream):**
   - HTTP/2에서 다중화는 여러 개의 독립적인 스트림을 통해 이뤄집니다. 각 스트림은 요청이나 응답을 나타냅니다. 

2. **스트림 식별자 (Stream Identifier):**
   - 각 스트림은 고유한 스트림 식별자를 가지며, 이를 통해 어떤 요청과 응답이 어떤 스트림에 속하는지 식별합니다.

3. **프레임 (Frame):**
   - 다중화는 여러 개의 프레임을 하나의 TCP 연결을 통해 동시에 전송합니다. 각 프레임은 특정 스트림에 속하는 데이터의 조각을 나타냅니다.

4. **우선순위 부여:**
   - HTTP/2는 각 스트림에 대해 우선순위를 부여할 수 있습니다. 서버와 클라이언트는 중요한 요청에 대해 더 높은 우선순위를 부여하여 특정 요청이 먼저 처리되도록 할 수 있습니다.

HTTP/2의 다중화 기술은 이러한 방식으로 동작하여 여러 요청과 응답을 효율적으로 처리하고 성능을 향상시킵니다. 
이는 특히 웹 페이지 로딩 속도를 높이고, 더 효율적으로 리소스를 활용할 수 있도록 도와줍니다.









------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
------------ [12] HTTP/2에서 HTTP Req/Res 메시지를 어떻게 압축하는지 설명합니다. ------------

Req/Res의 메세지를 압축
binary 프로토콜    : 바이너리 형태로 데이터를 압축해서 보낸다.
Multiplexing      : 하나의 stream으로 정보를 전달함.
header 압축        : 2가지 방식: static table과 dynamic table 따로 존재함.
                  static      : 기본적인 것들 (get, put 등등) 사전식으로 저장 숫자로 바꿈 (그러면 get 대신에 2를 보냄)
                  dynamic     :  이 client가 이 서버에 붙을 때 반드시 필요한 것들을 동적으로 할당한다. 
                                 특정 서버에 대해서는 달라자지만, 계속해서 정보를 교환 및 통신할 때 저장되는 데이터
                  + Huffman코드 -> 값이 변하지만 original에서 약간 변하는 것 / liner하게 변하는 것
                                    동영상처럼 (1과 10의 값의 차이로 영상을 보간하는 방식) 이미지를 구성한다.
우선 순위 지정       : Stream별로 우선 순위를 지정함 / => 중요한 리소스의 처리 지연을 방지
server push         : 클라이언트가 요청하지 않아도 필요가 예상되는 리소스를 서버가 미리 전송


------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[13] HTTP/3는 HTTP/2가 (TCP를 사용하기 때문에 해결하지 못하는) 어떤 문제점을 해결하고 있는지, 네트워크에서의 에러 발생과 초기 연결 관점에서 설명합니다.



HTTP/3는 HTTP/2에서 발생하는 몇 가지 문제를 해결하기 위해 개발되었습니다. 
주요한 변경 중 하나는 전송 프로토콜로 TCP 대신에 UDP를 사용한다는 것입니다. 
이로써 HTTP/3는 몇 가지 이점을 얻게 되었습니다.

1. **Head-of-line Blocking 문제 해결:**
   -  HTTP/2에서는 한 번에 하나의 메시지만을 처리할 수 있는 "Head-of-line Blocking" 문제가 발생할 수 있습니다. 
      만약 하나의 패킷이 손실되면 해당 패킷 이후의 모든 패킷이 대기해야 합니다. 
      이러한 문제는 HTTP/3에서는 QUIC 프로토콜을 사용하여 완화됩니다. 
      QUIC은 패킷 간의 독립성을 제공하므로 손상된 패킷이 다른 패킷에 영향을 미치지 않습니다.

2. **초기 연결 지연 완화:**
   -  TCP는 핸드쉐이크와 연결 설정에 대한 라운드 트립 시간(RTT)을 필요로 합니다. 
      이는 초기 연결 시간을 늘릴 수 있습니다. HTTP/3는 QUIC을 사용하며, QUIC은 0-RTT(Zero Round Trip Time)를 지원합니다. 
      이는 이전에 연결한 클라이언트와 서버 간의 정보를 저장하고 재사용함으로써 초기 연결 지연을 줄일 수 있습니다.

3. **네트워크 환경에서의 유연성:**
   -  TCP는 패킷 손실 시에 재전송을 위해 기다려야 하는데, 이는 네트워크 환경에서 추가적인 지연을 초래할 수 있습니다. 
      QUIC은 패킷 레벨에서 손실을 처리하고 빠르게 재전송하므로, 불안정한 네트워크에서도 더 나은 성능을 제공합니다.

4. **UDP 사용:**
   -  HTTP/3는 TCP가 아닌 UDP를 기반으로 하는 QUIC 프로토콜을 사용합니다. 
      UDP는 연결 설정 및 해제에 필요한 라운드 트립 타임이 적으며, 더 낮은 지연을 제공합니다. 
      또한, UDP는 상태를 유지하지 않기 때문에 서버 부하를 감소시키고 더 효율적인 연결 관리를 가능케 합니다.

HTTP/3는 이러한 기술적인 개선을 통해 더 나은 성능과 안정성을 제공하며, 특히 불안정한 네트워크 환경에서도 빠르고 효율적인 통신을 가능케 합니다.




------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[14] SIP 프로토콜을 사용하여 음성 전화를 하는 경우, 발신자와 착신자 간의 연결 설정과 해제 과정을 주요 메시지를 사용하여 설명합니다.
SIP(세션 초기화 프로토콜)는 음성 통화 및 멀티미디어 세션을 설정, 변경 및 종료하기 위한 프로토콜로, 주로 VoIP(Voice over Internet Protocol) 서비스에서 사용됩니다. SIP를 사용하여 음성 전화를 할 때, 발신자와 착신자 간의 연결 설정 및 해제 과정은 주요 SIP 메시지를 통해 이루어집니다.

### 연결 설정 과정:

1. **INVITE (초대):**
   - 발신자는 SIP INVITE 메시지를 사용하여 착신자에게 통화를 초대합니다. 이 메시지에는 통화에 필요한 정보와 SDP(Session Description Protocol) 등이 포함됩니다.

2. **100 Trying (시도 중):**
   - 착신자는 SIP 100 Trying 응답을 보내어 INVITE 메시지를 수신했음을 알립니다. 이 응답은 아직 최종적인 응답이 아니며, 처리 중임을 나타냅니다.

3. **180 Ringing (벨 울림):**
   - 착신자가 전화기를 울리게 하기 위해 SIP 180 Ringing 응답을 보낼 수 있습니다. 이것은 여전히 통화가 진행 중이며 벨이 울리고 있다는 것을 나타냅니다.

4. **200 OK (성공):**
   - 착신자가 수락하여 통화를 받을 경우, SIP 200 OK 응답을 발신자에게 보냅니다. 이 응답에는 SDP 등이 포함되어 있어 통화에 필요한 정보를 함께 제공합니다.

5. **ACK (확인):**
   - 발신자는 수락 응답을 확인하기 위해 SIP ACK 메시지를 보냅니다. 이로써 통화가 확립되고 양 측 간에 음성 데이터 전송이 시작됩니다.

### 연결 해제 과정:

1. **BYE (종료):**
   - 통화를 종료하려는 한 측이 SIP BYE 메시지를 상대방에게 보냅니다.

2. **200 OK (성공):**
   - 상대방은 BYE 메시지를 받고 통화를 종료할 수 있음을 의미하는 SIP 200 OK 응답을 보냅니다.

3. **ACK (확인):**
   - 종료 응답을 확인하기 위해 상대방은 SIP ACK 메시지를 보냅니다.

이러한 메시지 교환을 통해 SIP는 음성 전화의 연결 설정 및 해제를 담당하며, 이 프로세스는 두 사용자 간의 통화를 관리하는 데 중요한 역할을 합니다.




------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[15] WebRTC에서 STUN 서버와 TURN 서버의 역할에 대해서 설명합니다.
WebRTC(웹 실시간 통신)는 웹 브라우저 간에 실시간 통신을 가능케 하는 개방형 프로젝트입니다. WebRTC를 사용하는 응용 프로그램은 두 피어(peer) 간의 미디어 및 데이터 전송을 활성화하며, 이때 STUN 서버와 TURN 서버가 중요한 역할을 합니다.

### STUN (Session Traversal Utilities for NAT):

STUN 서버는 주로 네트워크 주소 변환(NAT) 뒤에 있는 디바이스의 공인된 IP 주소 및 포트를 확인하는 데 사용됩니다. WebRTC 피어는 서로 직접 통신하려고 시도하지만, NAT 뒤에 있는 경우 직접적인 연결이 어려울 수 있습니다. STUN은 다음과 같은 역할을 합니다.

1. **공인 IP 주소 및 포트 검색:**
   - WebRTC 피어는 STUN 서버에게 자신의 IP 주소 및 포트 정보를 요청합니다. 이 정보는 NAT를 통과한 후 공인 네트워크에 노출된 주소입니다.

2. **NAT 탐지:**
   - STUN은 피어 간의 연결이 어떤 형태로 되어 있는지(Full Cone, Restricted Cone, Port Restricted Cone 등)를 확인하여 NAT의 타입을 감지합니다.

3. **ICE(Interactive Connectivity Establishment) 프레임워크와 통합:**
   - STUN은 ICE 프레임워크의 일부로 사용되어 피어 간에 가장 효과적인 통신 경로를 결정하는 데 도움을 줍니다.

### TURN (Traversal Using Relays around NAT):

TURN 서버는 STUN과는 달리 두 피어 간에 직접적인 연결이 불가능한 경우, 중계(relay) 역할을 합니다. 이는 주로 대칭형(NAT Symmetric) NAT나 방화벽 등에 의해 직접 통신이 차단된 경우에 사용됩니다.

1. **데이터 중계:**
   - TURN 서버는 데이터를 받아서 중계하고, 피어 간의 통신을 도와줍니다. TURN을 통해 중계된 데이터는 TURN 서버를 거쳐 전달되므로, 피어 간에 직접적인 연결이 어려운 경우에도 통신이 가능해집니다.

2. **대역폭 소비:**
   - TURN은 중계를 위해 서버 리소스를 사용하므로, 대역폭 소비가 증가할 수 있습니다. 따라서, 직접 통신이 가능한 경우에는 TURN을 사용하지 않고 직접 통신을 선호합니다.

WebRTC 애플리케이션은 일반적으로 STUN과 TURN을 함께 사용하여 최상의 연결을 확립하고, 가능한 경우 직접 통신을 선호하여 대역폭을 절약합니다.







------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[16] Cloud Computing이 시작하게된 계기를 Public Cloud 사업자와 사업을 시작하는 벤처 회사 입장에서 설명합니다.

Cloud Computing이 시작하게 된 계기는 다양한 요인들이 결합된 결과입니다. 특히, Public Cloud 사업자와 벤처 회사들은 다음과 같은 이유로 Cloud Computing을 채택하게 되었습니다.

### Public Cloud 사업자의 입장:

1. **자원 공유 및 경제성:**
   - Public Cloud는 여러 조직이 하나의 인프라를 공유하고 사용할 수 있도록 합니다. 이는 하드웨어 리소스를 효율적으로 활용하며, 비용을 절감할 수 있는 경제적인 모델을 제공합니다.

2. **스케일링과 탄력성:**
   - Public Cloud는 필요에 따라 자원을 늘리거나 축소할 수 있는 스케일링 기능을 제공합니다. 이는 트래픽이나 작업 부하의 변동에 유연하게 대응할 수 있도록 도와줍니다.

3. **글로벌 리소스 제공:**
   - Public Cloud 사업자들은 세계 각지에 데이터 센터를 구축하여 글로벌한 서비스 제공이 가능하게 합니다. 이는 다양한 지역에서 사용자에게 낮은 지연 시간과 안정적인 서비스를 제공할 수 있도록 합니다.

4. **서비스 다양성:**
   - 다양한 서비스 모델을 제공하여 고객이 필요에 따라 IaaS(Infrastructure as a Service), PaaS(Platform as a Service), SaaS(Software as a Service) 등을 선택할 수 있습니다.

### 벤처 회사의 입장:

1. **비용 절감:**
   - 벤처 회사들은 초기에 대규모의 하드웨어 인프라를 구축하는 데 비용이 많이 들기 때문에, Public Cloud를 통해 초기 투자를 최소화하고 운영 비용을 절감할 수 있습니다.

2. **신속한 개발과 출시:**
   - Public Cloud는 개발자가 필요한 리소스를 빠르게 확보할 수 있도록 해주어 개발과 테스트를 신속하게 진행하고 새로운 제품이나 서비스를 빠르게 출시할 수 있게 합니다.

3. **스케일링 및 성장 관리:**
   - 벤처 회사는 예측하기 어려운 트래픽 증가에 대응하기 위해 필요한 만큼의 자원을 신속하게 확장할 수 있습니다. 이는 기업의 성장과 변화에 민첩하게 대응할 수 있도록 도와줍니다.

4. **보안 및 관리 간소화:**
   - Public Cloud 사업자들은 데이터 센터 보안 및 관리에 대한 전문성을 가지고 있으며, 이를 활용하여 벤처 회사들은 데이터 보안 및 관리를 신뢰할 수 있는 수준에서 간소화할 수 있습니다.

이러한 이유로 Public Cloud는 비즈니스의 민첩성, 효율성, 그리고 비용 효과를 향상시킬 수 있는 강력한 도구로 채택되어 왔습니다.




------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[17] Public Computing의 3대 모델을 나열하고, 각각 어떤 사항을 제공하는지 설명합니다.


Public Computing은 다양한 서비스 및 리소스를 공용으로 제공하는 컴퓨팅 모델들을 포함합니다. 주요한 Public Computing 모델로는 IaaS(Infrastructure as a Service), PaaS(Platform as a Service), 그리고 SaaS(Software as a Service)가 있습니다.

### 1. IaaS (Infrastructure as a Service):

- **제공 사항:**
  - IaaS는 가장 기본적인 Public Computing 모델로, 가상화된 하드웨어 리소스를 제공합니다. 이에는 가상 머신, 스토리지, 네트워킹 등이 포함됩니다.

- **특징 및 이점:**
  - 사용자는 가상 머신의 운영체제부터 애플리케이션 및 데이터까지 모든 것을 스스로 관리합니다.
  - 확장성이 뛰어나며, 사용자는 필요에 따라 가상 서버 및 스토리지를 빠르게 확장하거나 축소할 수 있습니다.
  - 사용자는 운영체제, 미들웨어, 애플리케이션을 직접 설치하고 관리할 수 있습니다.

### 2. PaaS (Platform as a Service):

- **제공 사항:**
  - PaaS는 개발 및 배포를 위한 플랫폼을 제공합니다. 이는 데이터베이스, 개발 도구, 운영체제, 실행 환경 등을 포함합니다.

- **특징 및 이점:**
  - 개발자는 애플리케이션을 개발하고 배포하는 데 필요한 기반 인프라를 거의 신경 쓰지 않고 개발에 집중할 수 있습니다.
  - 플랫폼은 자동으로 스케일링, 로드 밸런싱, 보안 패치 등을 관리하여 개발자의 부담을 줄입니다.
  - 다양한 개발 환경 및 언어를 지원하며, 개발 주기를 단축하고 효율성을 증가시킵니다.

### 3. SaaS (Software as a Service):

- **제공 사항:**
  - SaaS는 완전한 소프트웨어 응용 프로그램을 인터넷을 통해 제공합니다. 사용자는 웹 브라우저를 통해 해당 소프트웨어에 액세스합니다.

- **특징 및 이점:**
  - 사용자는 소프트웨어를 구매하거나 설치할 필요가 없습니다. 모든 서비스는 클라우드에서 제공되므로 웹 브라우저만 있으면 어디서나 액세스할 수 있습니다.
  - 유지보수 및 업그레이드는 서비스 제공자가 담당하며, 사용자는 최신 버전의 소프트웨어를 자동으로 받습니다.
  - 다양한 응용 프로그램을 구독하고 사용할 수 있어 비용 효율적입니다.

이러한 Public Computing 모델들은 각각의 특성에 따라 사용자에게 다양한 유연성과 편의성을 제공하며, 기업들은 자원과 비용을 효율적으로 관리할 수 있습니다.







------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[18] EC2와 S3가 무엇인지 설명합니다.

Amazon EC2 (Elastic Compute Cloud)와 Amazon S3 (Simple Storage Service)는 Amazon Web Services (AWS)에서 제공하는 클라우드 컴퓨팅 서비스의 일부입니다.

### Amazon EC2 (Elastic Compute Cloud):

- **용도 및 특징:**
  - Amazon EC2는 가상 서버를 제공하는 IaaS(Infrastructure as a Service) 서비스입니다.
  - 사용자는 필요에 따라 가상 머신을 시작하고 중지할 수 있으며, 다양한 운영체제 및 애플리케이션을 실행할 수 있습니다.

- **주요 기능:**
  1. **가상 머신 인스턴스:** 사용자는 EC2에서 가상 머신을 선택하고 시작할 수 있습니다.
  2. **다양한 인스턴스 유형:** 사용자는 서버의 크기, 성능 및 구성을 조절하기 위해 다양한 인스턴스 유형을 선택할 수 있습니다.
  3. **스케일링 및 탄력성:** 필요에 따라 인스턴스를 확장하거나 축소하여 트래픽이나 작업 부하에 대응할 수 있습니다.

- **활용 사례:**
  - 웹 애플리케이션 호스팅, 데이터베이스 실행, 컴퓨터 자원이 필요한 애플리케이션 실행 등에 사용됩니다.

### Amazon S3 (Simple Storage Service):

- **용도 및 특징:**
  - Amazon S3는 객체 스토리지 서비스로서 데이터를 안전하게 저장하고 검색할 수 있는 스케일러블한 스토리지를 제공합니다.
  - 데이터는 버킷(Bucket)이라는 컨테이너에 저장되며, 각 객체는 고유한 키를 가지고 있습니다.

- **주요 기능:**
  1. **데이터 저장 및 검색:** 사용자는 데이터를 S3 버킷에 업로드하고 검색할 수 있습니다.
  2. **데이터 버전 관리:** 버전 관리를 활성화하여 이전 버전의 객체를 보존하고 관리할 수 있습니다.
  3. **정적 웹 호스팅:** S3를 사용하여 정적 웹 사이트를 호스팅할 수 있습니다.

- **활용 사례:**
  - 정적 및 동적 웹 사이트 호스팅, 백업 및 아카이빙, 빅 데이터 분석, 애플리케이션 데이터 저장 등에 사용됩니다.

Amazon EC2와 Amazon S3는 AWS의 핵심 서비스로서, 기업은 이러한 서비스를 조합하여 다양한 애플리케이션을 실행하고 데이터를 효율적으로 관리할 수 있습니다.




------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[20] Virtual Machine 기반의 Computing의 Guest OS over Host OS이 문제로 작용한 사용자는 누구이며, 왜 문제인지 설명합니다.

Virtual Machine(가상 머신)에서 Guest OS가 Host OS 위에서 실행될 때의 문제는 주로 엔드 사용자, 즉 가상 머신을 사용하는 개발자, 시스템 관리자, 또는 기타 IT 전문가 등에게 영향을 미칩니다.

### 사용자:

1. **성능 저하:**
   - Virtual Machine에서 Guest OS가 Host OS 위에서 동작하면서 추가적인 계층이 발생하므로 성능에 영향을 미칠 수 있습니다. 특히, I/O 작업이나 네트워크 트래픽과 같은 작업에서 성능 저하가 발생할 수 있습니다.

2. **자원 소비:**
   - 각 가상 머신은 자체 운영체제와 응용 프로그램을 실행하므로, 물리적인 자원(메모리, CPU 등)을 공유하게 됩니다. 이로 인해 물리적인 호스트 자원이 부족한 경우 가상 머신 간의 자원 경합이 발생할 수 있습니다.

3. **호환성 문제:**
   - 특정 응용 프로그램이나 하드웨어 기능이 가상 머신에서 정상적으로 동작하지 않을 수 있습니다. 이는 가상 머신의 환경이 물리적인 환경과 다를 수 있기 때문입니다.

### 왜 문제인가:

1. **성능 문제:**
   - 성능 저하는 가상 머신의 동작 방식과 가상화 레이어 때문에 발생하는데, 이는 특히 높은 성능을 요구하는 애플리케이션에서 문제가 될 수 있습니다.

2. **자원 소비와 경합:**
   - 자원 소비 및 경합은 여러 가상 머신이 하나의 호스트에서 실행될 때 발생할 수 있는 문제입니다. 이는 각 가상 머신 간의 자원 할당 및 관리에 대한 효율적인 전략이 필요하다는 것을 의미합니다.

3. **호환성 문제:**
   - 특히 하이퍼바이저나 가상화 소프트웨어의 업데이트나 변경으로 인해 호환성 문제가 발생할 수 있습니다. 특정 애플리케이션이나 운영체제가 지원되지 않는 경우가 있을 수 있습니다.

가상 머신은 효율적인 리소스 활용과 유연성을 제공하지만, 위와 같은 문제로 인해 성능 및 호환성 등의 측면에서 고려가 필요합니다. 현대의 가상화 기술은 이러한 문제들을 해결하기 위해 지속적으로 발전하고 있습니다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[21] Container 기술이 Guest OS over Host OS 문제를 해결할 수 있는 이유와, Container에 포함되는 내용물은 무엇인지 설명합니다.

Container 기술은 가상 머신과는 달리 Guest OS over Host OS 문제를 해결할 수 있는 효과적인 방법을 제공합니다. 이를 가능케 하는 주요 이유들은 다음과 같습니다:

### 1. 공유 커널 (Shared Kernel):

- **가상 머신:** 각 가상 머신은 독립적인 운영체제를 가지고 있어, Guest OS와 Host OS 사이에는 가상화된 하드웨어 인터페이스 및 각종 레이어가 있습니다.

- **컨테이너:** 모든 컨테이너는 호스트 시스템과 동일한 커널을 공유합니다. 따라서 컨테이너는 Guest OS를 가지지 않으며, 호스트 시스템의 커널 위에서 직접 실행됩니다.

### 2. 경량성과 빠른 시작:

- **가상 머신:** 가상 머신은 완전한 운영체제 이미지를 가지고 있어 크기가 크고, 가동하는 데 상당한 시간이 소요될 수 있습니다.

- **컨테이너:** 컨테이너는 필요한 라이브러리와 응용프로그램을 포함하는데, 이는 가상 머신보다 훨씬 경량하며, 컨테이너를 빠르게 시작하고 중지할 수 있습니다.

### 3. 확장성과 효율성:

- **가상 머신:** 각 가상 머신은 자체 운영체제를 가지고 있어 메모리 및 디스크 공간을 많이 차지하고, 여러 개의 가상 머신을 운영하는 데 리소스가 소모됩니다.

- **컨테이너:** 컨테이너는 공유된 커널을 사용하므로 오버헤드가 감소하며, 여러 개의 컨테이너를 호스팅하는 것이 효율적입니다.

### Container에 포함되는 내용물:

컨테이너에는 다음과 같은 내용물이 포함됩니다:

1. **애플리케이션 코드:** 컨테이너에는 실행할 애플리케이션의 코드 및 실행 파일이 포함됩니다.

2. **라이브러리 및 종속성:** 필요한 라이브러리 및 종속성은 컨테이너 내에 포함되어 있어, 호스트 시스템에 영향을 미치지 않고 실행될 수 있습니다.

3. **환경 변수 및 설정:** 애플리케이션의 환경 변수나 설정 정보는 컨테이너에 포함되어, 컨테이너가 동일한 환경에서 일관되게 실행될 수 있도록 합니다.

4. **실행 환경 및 설정:** 컨테이너 실행을 위한 설정과 필요한 실행 환경이 함께 패키징되어 있습니다.

Container 기술은 이러한 특징들을 통해 확장성, 효율성, 빠른 배포 등의 이점을 제공하며, 가상 머신과는 다른 사용 사례에 적합한 솔루션을 제공합니다.



------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[22] Microservice 개념에 의해서 만들어지는 프로그래밍(들)이 과거 하나의 강력한 프로그램으로 만드는 경우 대비 가질수 있는 장점들을 기술적/비기술적인 측면에서 설명해 봅니다.
Microservices 아키텍처는 소프트웨어를 작은, 독립적인 서비스로 나누어 개발하고 운영하는 방식입니다. 이는 하나의 강력한 프로그램으로 모든 기능을 통합하는 전통적인 몰리틱스(monoliths) 방식과 대비됩니다. Microservices로의 전환은 기술적 및 비기술적 측면에서 여러 이점을 가져옵니다.

### 기술적 측면:

1. **확장성 및 유연성:**
   - Microservices는 각각이 독립적으로 배포되고 운영되므로, 필요에 따라 특정 서비스를 확장하거나 업데이트할 수 있습니다. 이는 시스템이 더 유연하게 대응하고 확장할 수 있음을 의미합니다.

2. **기술 스택 다양성:**
   - 서비스 간의 독립성으로 인해 각각의 Microservice는 필요에 따라 다른 기술 스택과 언어를 사용할 수 있습니다. 이는 최적의 도구 및 기술을 선택하여 각 서비스의 요구사항에 맞게 개발할 수 있는 유연성을 제공합니다.

3. **빠른 배포 및 롤백:**
   - 각 Microservice는 독립적으로 배포될 수 있기 때문에 전체 애플리케이션의 배포 프로세스가 간소화됩니다. 또한, 특정 Microservice의 문제가 발생한 경우 해당 서비스만 롤백할 수 있습니다.

4. **스케일 아웃 용이성:**
   - 특정 Microservice의 트래픽이 증가하면 해당 서비스만을 스케일 아웃할 수 있습니다. 전체 애플리케이션을 단일 단위로 확장하는 것보다 효율적으로 자원을 활용할 수 있습니다.

### 비기술적 측면:

1. **빠른 개발과 릴리스:**
   - 각 Microservice는 독립적으로 개발, 테스트, 배포되므로 전체 애플리케이션을 단일 코드베이스로 관리하는 것보다 개발과 배포가 빠릅니다.

2. **팀의 독립성:**
   - 각 Microservice는 독립적인 팀이 책임지고 관리할 수 있습니다. 이는 큰 조직에서도 작은 팀이 자율적으로 작업할 수 있음을 의미하며, 팀 간의 의존성을 최소화합니다.

3. **유연한 조직 구조:**
   - Microservices는 서비스 간의 느슨한 결합을 가지고 있기 때문에 조직 내에서도 팀 간의 의사 소통과 협력이 증가할 수 있습니다. 또한, 특정 Microservice에 대한 업데이트가 다른 팀에 미치는 영향이 최소화됩니다.

4. **기존 시스템 통합 용이성:**
   - 기존의 모놀리식 시스템을 Microservices로 전환할 수 있으며, 새로운 기능을 추가하거나 기존 기능을 개선하기 위한 확장이 용이합니다.

Microservices는 기술적으로 더 뛰어난 효율성과 유연성을 제공하며, 비기술적인 측면에서는 조직의 민첩성과 협력성을 향상시킵니다.

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[23] Game 서버 중, Master Server와 Game (Logic) Server의 역할에 대해서 설명합니다.


게임 서버 아키텍처에서 Master Server와 Game (Logic) Server는 각각 다른 역할을 수행하며, 게임 플레이를 조율하고 관리합니다.

### 1. Master Server:

- **역할:**
  - Master Server는 게임 서버 아키텍처에서 중앙 집중적인 역할을 수행합니다. 주로 로비 시스템이나 게임 서버 디스커버리 등과 같은 중앙화된 기능을 담당합니다.

- **주요 기능:**
  1. **게임 서버 디스커버리:** Master Server는 게임 서버의 목록과 상태를 추적하고, 플레이어가 게임에 참여할 수 있는 서버를 찾는 데 사용됩니다.
  
  2. **로비 및 매치메이킹:** 플레이어는 Master Server를 통해 로비에 참여하고, 매치메이킹을 통해 다른 플레이어와 게임을 시작할 수 있습니다.
  
  3. **플레이어 관리:** 플레이어 인증, 계정 관리, 통계 수집 등과 같은 플레이어 관리 기능을 수행합니다.

- **예시:**
  - 플레이어가 게임을 실행하면, Master Server에 연결하여 사용 가능한 게임 서버 목록을 가져오고, 로비에 참여하여 다른 플레이어들과 매치메이킹을 수행할 수 있습니다.

### 2. Game (Logic) Server:

- **역할:**
  - Game Server는 게임 플레이의 핵심 로직과 상태를 관리하는 서버입니다. 각 게임에 따라 여러 개의 Game Server가 운영될 수 있습니다.

- **주요 기능:**
  1. **게임 로직 실행:** 실제 게임 플레이의 로직을 실행하고, 플레이어의 행동을 처리하여 게임 상태를 업데이트합니다.
  
  2. **플레이어 간 통신:** 플레이어들 간의 상호 작용, 채팅, 무역 등과 같은 통신을 처리합니다.
  
  3. **게임 상태 관리:** 현재 게임의 상태를 유지하고, 게임의 진행 상황을 모든 플레이어에게 동기화합니다.
  
  4. **점수 및 통계 관리:** 게임 진행 중에 플레이어의 점수, 성과 및 통계를 관리합니다.

- **예시:**
  - 플레이어가 Master Server를 통해 선택한 게임 서버에 연결하면, 해당 Game Server에서 게임 플레이가 시작되고, 게임 로직이 실행됩니다.

이와 같이 Master Server와 Game Server는 협력하여 게임을 관리하고 제공하는 역할을 수행합니다. Master Server는 중앙화된 서비스를 제공하고, Game Server는 특정 게임의 로직을 실행하며 플레이어 간 상호 작용을 관리합니다.
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
[24] Game 서버가 제공하는 실시간 성 서비스는 어떤 것들이 있는지 설명합니다. (네트워크 기능, 콘텐츠 생성 기능 등 측면을 강의노트의 서버 예제들을 참조하여 답변함)


게임 서버가 제공하는 실시간 서비스는 다양한 측면에서 풍부한 기능을 포함하고 있습니다. 아래는 게임 서버가 제공하는 주요 실시간 서비스의 예시입니다.

### 1. **네트워크 기능:**

- **플레이어 통신 관리:**
  - 게임 서버는 플레이어 간의 통신을 관리하며, 플레이어 간의 메시지 교환, 채팅, 콜라보레이션, 무역 등을 처리합니다.

- **인터페이스 제공:**
  - 게임 서버는 클라이언트와의 통신을 위한 API나 소켓 기반의 인터페이스를 제공하여 클라이언트와의 실시간 통신을 용이하게 합니다.

### 2. **콘텐츠 생성 기능:**

- **실시간 이벤트 생성:**
  - 게임 서버는 특정 상황이나 조건에 따라 실시간으로 이벤트를 생성하고 플레이어에게 전달합니다. 예를 들어, 특별 이벤트, 임무 업데이트, 보상 획득 등이 해당됩니다.

- **동적 환경 제공:**
  - 게임 서버는 콘텐츠를 동적으로 생성하여 플레이어에게 새로운 경험을 제공합니다. 이는 게임 맵, 캐릭터 등을 실시간으로 업데이트하고 반영하는 것을 의미합니다.

### 3. **게임 로직 및 상태 관리:**

- **실시간 게임 로직 실행:**
  - 게임 서버는 플레이어의 입력에 대한 게임 로직을 처리하고, 게임 상태를 실시간으로 업데이트하여 모든 플레이어에게 동기화합니다.

- **이벤트 및 행동 처리:**
  - 게임 서버는 플레이어의 행동에 대한 이벤트를 감지하고, 적절한 처리를 통해 게임 세계의 상태를 변경합니다. 예를 들어, 플레이어의 이동, 스킬 사용, 공격 등이 해당됩니다.

### 4. **보안 및 안전성:**

- **인증 및 권한 관리:**
  - 게임 서버는 플레이어를 식별하고, 인증하여 안전한 플레이를 보장합니다. 또한, 권한 관리를 통해 특정 기능에 대한 접근을 제어합니다.

- **방어적 조치:**
  - 게임 서버는 침입 탐지, 방화벽 등을 통해 보안을 강화하고, 부정행위로부터 게임을 보호합니다.

### 5. **다양한 서비스 지원:**

- **매치메이킹 및 랭킹 시스템:**
  - 게임 서버는 플레이어 간의 매치메이킹을 지원하고, 랭킹 시스템을 통해 경쟁을 촉진합니다.

- **실시간 통계 및 분석:**
  - 게임 서버는 실시간 통계와 분석을 수행하여 플레이어 행동, 게임 성과 등을 모니터링하고 개선에 활용합니다.

이러한 서비스들은 게임 서버를 통해 플레이어에게 더 풍부하고 동적인 게임 경험을 제공하며, 다양한 기능을 실시간으로 처리하여 게임의 품질과 흥미를 향상시킵니다.
------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------